{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "ResNet-based Keypoint Estimator\n",
    "\"\"\"\n",
    "class Configuration:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        self.temp = {\n",
    "            'train_data': '/home/sasank/Documents/GitRepos/Sasank_JTML_seg/data/3_2_22_fem/train_3_2_22_fem.csv',\n",
    "            'val_data': '/home/sasank/Documents/GitRepos/Sasank_JTML_seg/data/3_2_22_fem/val_3_2_22_fem.csv',\n",
    "            'test_data': '/home/sasank/Documents/GitRepos/Sasank_JTML_seg/data/3_2_22_fem/test_3_2_22_fem.csv'\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.init = {\n",
    "            'PROJECT_NAME': 'Keypoint Estimation',\n",
    "            'MODEL_NAME': 'Tib_64KP',\n",
    "            'RUN_NAME': time.strftime('%Y-%m-%d-%H-%M-%S'),\n",
    "            'WANDB_RUN_GROUP': 'Local',\n",
    "            'FAST_DEV_RUN': False,  # Runs inputted batches (True->1) and disables logging and some callbacks\n",
    "            'MAX_EPOCHS': 10,\n",
    "            'MAX_STEPS': -1,    # -1 means it will do all steps and be limited by epochs\n",
    "            'STRATEGY': None    # This is the training strategy. Should be 'ddp' for multi-GPU (like HPG)\n",
    "        }\n",
    "        self.etl = {\n",
    "            'RAW_DATA_FILE': -1,\n",
    "            'DATA_DIR': \"data\",\n",
    "            # Lol what is this?\n",
    "            'KEYPOINT_DIRECTORY': \"keypoints\",\n",
    "            'KEYPOINT_TXT_FILES': ['tib_KPlabels_16.txt'],\n",
    "            'VAL_SIZE':  0.2,       # looks sus\n",
    "            'TEST_SIZE': 0.01,      # I'm not sure these two mean what we think\n",
    "            #'random_state': np.random.randint(1,50)\n",
    "            # HHG2TG lol; deterministic to aid reproducibility\n",
    "            'RANDOM_STATE': 42,\n",
    "\n",
    "            'CUSTOM_TEST_SET': False,\n",
    "            'TEST_SET_NAME': '/my/test/set.csv'\n",
    "        }\n",
    "\n",
    "        self.dataset = {\n",
    "            'DATA_NAME': 'Ten_Dogs_64KP',\n",
    "            'SUBSET_PIXELS': True,\n",
    "            'IMAGE_HEIGHT': 1024,\n",
    "            'IMAGE_WIDTH': 1024,\n",
    "            'MODEL_TYPE': 'tib',        # how should we do this? not clear this is still best...\n",
    "            'CLASS_LABELS': {0: 'bone', 1: 'background'},\n",
    "            'NUM_KEY_POINTS': 64,\n",
    "            'IMG_CHANNELS': 1,      # Is this different from self.module['NUM_IMAGE_CHANNELS']\n",
    "            'STORE_DATA_RAM': False,\n",
    "            'IMAGE_THRESHOLD': 0,\n",
    "            'USE_ALBUMENTATIONS': False,\n",
    "\n",
    "            # What do these do?\n",
    "            'NUM_PRINT_IMG' : 1,\n",
    "            'KP_PLOT_RAD' : 3,\n",
    "\n",
    "            #'NUM_POINTS' : 128,\n",
    "\n",
    "            'GAUSSIAN_STDDEV' : 5,\n",
    "            'GAUSSIAN_AMP' : 1e3,\n",
    "\n",
    "            'STORE_DATA_RAM' : False,\n",
    "\n",
    "            'CROP_IMAGES' : False,\n",
    "            'CROP_MIN_X' : 0.29,\n",
    "            'CROP_MAX_X' : 0.84,\n",
    "            'CROP_MIN_Y' : 0.45,\n",
    "            'CROP_MAX_Y' : 0.95,\n",
    "            \n",
    "            'IMAGES_PER_GRID': 1,\n",
    "            'per_grid_image_count_height' : 1, \n",
    "            'per_grid_image_count_width' : 1\n",
    "        }\n",
    "\n",
    "        \"\"\"\n",
    "        # segmentation_net_module needs to be below dataset because it uses dataset['IMG_CHANNELS']\n",
    "        self.keypoint_net_module = {\n",
    "            'NUM_KEY_POINTS': 128,\n",
    "            'NUM_IMG_CHANNELS': self.dataset['IMG_CHANNELS']\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        self.datamodule = {\n",
    "            'IMAGE_DIRECTORY': '/media/sasank/LinuxStorage/Dropbox (UFL)/Canine Kinematics Data/TPLO_Ten_Dogs_grids/',\n",
    "            'CKPT_FILE': None,\n",
    "            'USE_NAIVE_TEST_SET': False,\n",
    "            'BATCH_SIZE': 2,\n",
    "            'SHUFFLE': True,        # Only for training; for test and val this is set in the datamodule script to False\n",
    "            'NUM_WORKERS': 2,\n",
    "            'PIN_MEMORY': False\n",
    "            #'SUBSET_PIXELS': True - this is now in dataset\n",
    "        }\n",
    "\n",
    "\n",
    "        # hyperparameters for training\n",
    "        self.hparams = {\n",
    "            'LOAD_FROM_CHECKPOINT': False,\n",
    "            'learning_rate': 1e-3\n",
    "        }\n",
    "\n",
    "        #self.transform = None\n",
    "        self.transform = \\\n",
    "        A.Compose([\n",
    "            # Let's do only rigid transformations for now\n",
    "            A.HorizontalFlip(p=0.9),\n",
    "            A.VerticalFlip(p=0.9),\n",
    "            A.RandomRotate90(p=0.9),\n",
    "            A.Transpose(p=0.9),\n",
    "            #A.RandomGamma(always_apply=False, p = 0.5,gamma_limit=(10,300)),\n",
    "            #A.ShiftScaleRotate(always_apply = False, p = 0.5,shift_limit=(-0.06, 0.06), scale_limit=(-0.1, 0.1), rotate_limit=(-180,180), interpolation=0, border_mode=0, value=(0, 0, 0)),\n",
    "            #A.Blur(always_apply=False, blur_limit=(3, 10), p=0.2),\n",
    "            #A.Flip(always_apply=False, p=0.5),\n",
    "            #A.InvertImg(always_apply=False, p=0.5),\n",
    "            #A.MultiplicativeNoise(always_apply=False, p=0.25, multiplier=(0.1, 2), per_channel=True, elementwise=True)\n",
    "            #A.ElasticTransform(always_apply=False, p=0.85, alpha=0.5, sigma=150, alpha_affine=50.0, interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None, approximate=False),\n",
    "            #A.CoarseDropout(always_apply = False, p = 0.25, min_holes = 1, max_holes = 100, min_height = 25, max_height=25),\n",
    "        ],\n",
    "        p=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import cv2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "\n",
    "from loss import kp_loss\n",
    "\n",
    "\n",
    "\n",
    "class KeypointDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, config, evaluation_type, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            config (config): Dictionary of vital constants about data.\n",
    "            store_data_ram (boolean): Taken from config.\n",
    "            evaluation_type (string): Dataset evaluation type (must be 'training', 'validation', or 'test')\n",
    "            num_points (int): Taken from config.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        # Create local copies of the arguments\n",
    "        self.config = config\n",
    "        self.num_points = self.config.dataset['NUM_KEY_POINTS']\n",
    "        self.transform = self.config.transform\n",
    "        \n",
    "        # Check that evaluation_type is valid and then store\n",
    "        if evaluation_type in ['train', 'val', 'test', 'naive']:\n",
    "            self.evaluation_type = evaluation_type\n",
    "        else:\n",
    "            raise Exception('Incorrect evaluation type! Must be either \\'train\\', \\'val\\', \\'test\\', or \\'naive\\'.')\n",
    "\n",
    "        # Load the data from the big_data CSV file into a pandas dataframe\n",
    "        #self.data = pd.read_csv(os.path.join(self.config.etl['DATA_DIR'], self.config.dataset['DATA_NAME'], self.evaluation_type + '_' + self.config.dataset['DATA_NAME'] + '.csv'))\n",
    "        self.data = pd.read_csv('/home/sasank/Documents/GitRepos/Stifle-Keypoints/data/Ten_Dogs_64KP/naive_Ten_Dogs_64KP.csv')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - 1   # Subtract 1 because the first row is the column names\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx += 1    # Add 1 because the first row is the column names\n",
    "\n",
    "        # Get the row of the dataframe\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # Get the image name\n",
    "        image_name = row['Image address']\n",
    "\n",
    "        # Get the image\n",
    "        image = io.imread(os.path.join(self.config.datamodule['IMAGE_DIRECTORY'], image_name))\n",
    "        full_image = image             # Save full image (no subset_pixels) for visualization\n",
    "\n",
    "        # Get the keypoint labels and segmentation labels\n",
    "        if self.config.dataset['MODEL_TYPE'] == 'fem':\n",
    "            kp_label = row['Femur 2D KP points']\n",
    "            seg_label = io.imread(os.path.join(self.config.datamodule['IMAGE_DIRECTORY'], row['Fem label address']))\n",
    "        elif self.config.dataset['MODEL_TYPE'] == 'tib':\n",
    "            kp_label = row['Tibia 2D KP points']\n",
    "            seg_label = io.imread(os.path.join(self.config.datamodule['IMAGE_DIRECTORY'], row['Tib label address']))\n",
    "        else:\n",
    "            raise Exception('Incorrect model type! Must be either \\'fem\\' or \\'tib\\'.')\n",
    "\n",
    "        kp_label = kp_label[2:-2]\n",
    "        kp_label = kp_label.split(']\\n [')\n",
    "        kp_label = [np.array([float(x) for x in list(filter(None, kp.split(' ')))]) for kp in kp_label]\n",
    "        kp_label = np.array(kp_label)\n",
    "        \n",
    "        # * Subset Pixels\n",
    "        if self.config.dataset['SUBSET_PIXELS'] == True:\n",
    "            label_dst = np.zeros_like(seg_label)\n",
    "            label_normed = cv2.normalize(seg_label, label_dst, alpha = 0, beta = 1, norm_type = cv2.NORM_MINMAX)\n",
    "            seg_label = label_normed\n",
    "\n",
    "            kernel = np.ones((30,30), np.uint8)\n",
    "            label_dilated = cv2.dilate(seg_label, kernel, iterations = 5)\n",
    "            image_subsetted = cv2.multiply(label_dilated, image)\n",
    "            image = image_subsetted\n",
    "\n",
    "        image = torch.FloatTensor(image[None, :, :]) # Store as byte (to save space) then convert when called in __getitem__\n",
    "        full_image = torch.FloatTensor(full_image[None, :, :]) # Store as byte (to save space) then convert when called in __getitem__\n",
    "        seg_label = torch.FloatTensor(seg_label[None, :, :])\n",
    "        #kp_label = torch.FloatTensor(kp_label.reshape(-1))      # Reshape to 1D array so that it's 2*num_keypoints long\n",
    "        kp_label = torch.FloatTensor(kp_label)          # kp_label is of shape (num_keypoints, 2)\n",
    "        assert kp_label.shape == (self.num_points, 2), \"Keypoint label shape is incorrect!\"\n",
    "        #print(\"kp_label.shape:\")\n",
    "        #print(kp_label.shape)\n",
    "\n",
    "\n",
    "    \n",
    "        # Form sample and transform if necessary\n",
    "        sample = {'image': image,\n",
    "                    'img_name': image_name,\n",
    "                    'kp_label': kp_label,\n",
    "                    'seg_label': seg_label,\n",
    "                    'full_image': full_image}\n",
    "        assert self.transform is not None, \"Transforms not implemented yet!\"\n",
    "        if self.transform and self.config.dataset['USE_ALBUMENTATIONS'] == True:\n",
    "            sample = self.transform(sample)     # TODO: Implement transforms. Seems like we'll have to reshape the keypoints to be num_keypoints x 2 instead of 2*num_keypoints x 1\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()\n",
    "dataset = KeypointDataset(config, 'naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.7.6 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../checkpoints/Tib64_200Epochs_better.ckpt`\n"
     ]
    }
   ],
   "source": [
    "from lit_KPResNet import KeypointNetModule\n",
    "\n",
    "CHECKPOINT_PATH = '/home/sasank/Documents/GitRepos/Stifle-Keypoints/checkpoints/Tib64_200Epochs_better.ckpt'\n",
    "model = KeypointNetModule.load_from_checkpoint(CHECKPOINT_PATH, config=config, wandb_run = None)\n",
    "\n",
    "csv_file = pd.read_csv('/home/sasank/Documents/GitRepos/PnP-Solver/kp_estimates/naive_Ten_Dogs_64KP_estimates_pr.csv')\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    image = sample['image']\n",
    "    img_name = sample['img_name']\n",
    "    image.unsqueeze_(0)\n",
    "    output = model(image)\n",
    "\n",
    "    # We will plot the outputs, which are 2D keypoints, to self.csv_file in the row that corresponds to the image name\n",
    "    keypoints = output.detach().cpu().numpy()\n",
    "    # Make the keypoints a 2D array of shape (num_keypoints, 2)\n",
    "    keypoints = keypoints.reshape(config.dataset['NUM_KEY_POINTS'], 2)\n",
    "    #keypoints.view(64,2)\n",
    "\n",
    "    # Find the row that corresponds to the image name\n",
    "    #self.csv_file.loc[self.csv_file['Image address'] == img_name]['Femur PR KP points'] = str(keypoints)\n",
    "    csv_file.loc[csv_file['Image address'] == img_name, 'Tibia PR KP points'] = str(keypoints)\n",
    "    #print(i, sample['image'].shape, sample['kp_label'].shape, sample['seg_label'].shape)\n",
    "\n",
    "    #model(sample['image'], sample['kp_label'], sample['seg_label'])\n",
    "\n",
    "csv_file.to_csv('/home/sasank/Documents/GitRepos/PnP-Solver/kp_estimates/naive_Ten_Dogs_64KP_estimates_pr.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m PRINT_DIR \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/media/sasank/LinuxStorage/Dropbox (UFL)/Canine Kinematics Data/image_check/pruned_tib/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Iterate through the dataset and print the shapes of the images and labels\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset)):\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mimage number: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i))\n\u001b[1;32m      5\u001b[0m     batch \u001b[39m=\u001b[39m dataset[i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "PRINT_DIR = '/media/sasank/LinuxStorage/Dropbox (UFL)/Canine Kinematics Data/image_check/pruned_tib/'\n",
    "# Iterate through the dataset and print the shapes of the images and labels\n",
    "for i in range(len(dataset)):\n",
    "    print(\"image number: \" + str(i))\n",
    "    batch = dataset[i]\n",
    "    images = batch['image']\n",
    "    kp_labels = batch['kp_label']\n",
    "    img_names = batch['img_name']\n",
    "    title = ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    num_images = images.shape[0]\n",
    "    num_keypoints = kp_labels.shape[0]\n",
    "    assert num_keypoints == 64, \"Number of keypoints is incorrect!\"\n",
    "    images = images.cpu()\n",
    "    kp_labels = kp_labels.cpu()\n",
    "    kp_labels = kp_labels.numpy()\n",
    "\n",
    "    output_image_vector = []\n",
    "\n",
    "    for i in range(0, num_images):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 10), squeeze=False)\n",
    "\n",
    "        # ! TODO: Is this the right way to do this? Is there something wrong here with offsets or something?\n",
    "        #kp_labels[i][:, 0] = +1 * kp_labels[i][:, 0] * 1024\n",
    "        kp_labels[:, 0] = +1 * kp_labels[:, 0] * 1024\n",
    "        #kp_labels[i][:, 1] = -1 * kp_labels[i][:, 1] * 1024 + 1024\n",
    "        kp_labels[:, 1] = -1 * kp_labels[:, 1] * 1024 + 1024\n",
    "        # Do some stuff so that img is shown correctly\n",
    "        img = images.numpy()\n",
    "        img = np.transpose(img, (1, 2, 0))  # Transpose the output so that it's the same way as img\n",
    "        img = np.dstack((img, img, img))    # Make it 3 channels\n",
    "        ax[0][0].imshow((img * 255).astype(np.uint8))  # The multiplying by 255 and stuff is so it doesn't get clipped or something\n",
    "\n",
    "        for j in range(num_keypoints):\n",
    "            #ax[0][0].text(labels[i][j, 0], labels[i][j, 1], str(j), color='m')        # Silenced this for now since we have 64 keypoints\n",
    "            ax[0][0].plot(kp_labels[j, 0], kp_labels[j, 1], color='orange', marker='.', markersize=5)\n",
    "            #ax[0][0].plot([kp_labels[i][j, 0], kp_preds[i][j, 0]], [labels[i][j, 1], preds[i][j, 1]], color='limegreen', linestyle='-')\n",
    "        image_name = img_names.split('/')[-1]    # Format img_names[i] so that only the part after the last '/' is shown\n",
    "        ax[0][0].set_title(title + ' {}'.format(image_name))\n",
    "        fig.savefig(os.path.join(PRINT_DIR, image_name))\n",
    "        output_image_vector.append(fig)\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jtml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
